package org.gnit.lucenekmp.queryparser.classic

import org.gnit.lucenekmp.analysis.Analyzer
import org.gnit.lucenekmp.document.DateTools
import org.gnit.lucenekmp.internal.hppc.IntHashSet
import org.gnit.lucenekmp.jdkport.StringReader
import org.gnit.lucenekmp.queryparser.charstream.CharStream
import org.gnit.lucenekmp.queryparser.charstream.FastCharStream
import org.gnit.lucenekmp.search.BooleanClause
import org.gnit.lucenekmp.search.Query
import org.gnit.lucenekmp.search.TermRangeQuery


/**
 * This class is generated by JavaCC.  The most important method is
 * [.parse].
 *
 * The syntax for query strings is as follows:
 * A Query is a series of clauses.
 * A clause may be prefixed by:
 *
 *  *  a plus (`+`) or a minus (`-`) sign, indicating
 * that the clause is required or prohibited respectively; or
 *  *  a term followed by a colon, indicating the field to be searched.
 * This enables one to construct queries which search multiple fields.
 *
 *
 * A clause may be either:
 *
 *  *  a term, indicating all the documents that contain this term; or
 *  *  a nested query, enclosed in parentheses.  Note that this may be used
 * with a `+`/`-` prefix to require any of a set of
 * terms.
 *
 *
 * Thus, in BNF, the query grammar is:
 * <pre>
 * Query  ::= ( Clause )*
 * Clause ::= ["+", "-"] [&lt;TERM&gt; ":"] ( &lt;TERM&gt; | "(" Query ")" )
</pre> *
 *
 *
 *
 * Examples of appropriately formatted queries can be found in the [query syntax
 * documentation]({@docRoot}/org/apache/lucene/queryparser/classic/package-summary.html#package.description).
 *
 *
 *
 *
 * In [TermRangeQuery]s, QueryParser tries to detect date values, e.g.
 * `date:[6/1/2005 TO 6/4/2005]` produces a range query that searches
 * for "date" fields between 2005-06-01 and 2005-06-04. Note that the format
 * of the accepted input depends on [the locale][.setLocale].
 * A [org.apache.lucene.document.DateTools.Resolution] has to be set,
 * if you want to use [DateTools] for date conversion.
 *
 *
 *
 * The date resolution that shall be used for RangeQueries can be set
 * using [.setDateResolution]
 * or [.setDateResolution]. The former
 * sets the default date resolution for all fields, whereas the latter can
 * be used to set field specific date resolutions. Field specific date
 * resolutions take, if set, precedence over the default date resolution.
 *
 *
 *
 * If you don't use [DateTools] in your index, you can create your own
 * query parser that inherits QueryParser and overwrites
 * [.getRangeQuery] to
 * use a different method for date conversion.
 *
 *
 *
 * Note that QueryParser is *not* thread-safe.
 *
 *
 * **NOTE**: there is a new QueryParser in contrib, which matches
 * the same syntax as this class, but is more modular,
 * enabling substantial customization to how a query is created.
 */
class QueryParser : QueryParserBase,
    QueryParserConstants {
    /** The default operator for parsing queries.
     * Use [QueryParserBase.setDefaultOperator] to change it.
     */
    enum class Operator {
        OR, AND
    }

    /** Create a query parser.
     * @param f  the default field for query terms.
     * @param a   used to find terms in the query text.
     */
    constructor(
        f: String,
        a: Analyzer
    ) : this(FastCharStream(StringReader(""))) {
        init(f, a)
    }

    /**
     * Set to true if phrase queries will be automatically generated
     * when the analyzer returns more than one term from whitespace
     * delimited text.
     * NOTE: this behavior may not be suitable for all languages.
     *
     *
     * Set to false if phrase queries should only be generated when
     * surrounded by double quotes.
     *
     *
     * The combination splitOnWhitespace=false and autoGeneratePhraseQueries=true
     * is disallowed.  See [LUCENE-7533](https://issues.apache.org/jira/browse/LUCENE-7533).
     */
    override var autoGeneratePhraseQueries: Boolean = false
        set(value) {
            require(!(!splitOnWhitespace && value)) { "setAutoGeneratePhraseQueries(true) is disallowed when getSplitOnWhitespace() == false" }
            field = value
        }

    /**
     * @see .setSplitOnWhitespace
     */
    fun getSplitOnWhitespace(): Boolean {
        return splitOnWhitespace
    }

    /**
     * Whether query text should be split on whitespace prior to analysis.
     * Default is `{@value #DEFAULT_SPLIT_ON_WHITESPACE}`.
     *
     *
     * The combination splitOnWhitespace=false and autoGeneratePhraseQueries=true
     * is disallowed.  See [LUCENE-7533](https://issues.apache.org/jira/browse/LUCENE-7533).
     */
    fun setSplitOnWhitespace(splitOnWhitespace: Boolean) {
        require(!(!splitOnWhitespace && autoGeneratePhraseQueries)) { "setSplitOnWhitespace(false) is disallowed when getAutoGeneratePhraseQueries() == true" }
        this.splitOnWhitespace = splitOnWhitespace
    }

    private var splitOnWhitespace = DEFAULT_SPLIT_ON_WHITESPACE

    // *   Query  ::= ( Clause )*
    // *   Clause ::= ["+", "-"] [<TERM> ":"] ( <TERM> | "(" Query ")" )
    @Throws(ParseException::class)
    fun Conjunction(): Int {
        var ret: Int = QueryParserBase.CONJ_NONE
        when (if (jj_ntk == -1) jj_ntk_f() else jj_ntk) {
            QueryParserConstants.AND, QueryParserConstants.OR -> {
                when (if (jj_ntk == -1) jj_ntk_f() else jj_ntk) {
                    QueryParserConstants.AND -> {
                        jj_consume_token(QueryParserConstants.AND)
                        ret = QueryParserBase.CONJ_AND
                    }

                    QueryParserConstants.OR -> {
                        jj_consume_token(QueryParserConstants.OR)
                        ret = QueryParserBase.CONJ_OR
                    }

                    else -> {
                        jj_la1[0] = jj_gen
                        jj_consume_token(-1)
                        throw ParseException()
                    }
                }
            }

            else -> {
                jj_la1[1] = jj_gen
            }
        }
        run { if ("" != null) return ret }
        throw Error("Missing return statement in function")
    }

    @Throws(ParseException::class)
    fun Modifiers(): Int {
        var ret: Int = MOD_NONE
        when (if (jj_ntk == -1) jj_ntk_f() else jj_ntk) {
            QueryParserConstants.NOT, QueryParserConstants.PLUS, QueryParserConstants.MINUS -> {
                when (if (jj_ntk == -1) jj_ntk_f() else jj_ntk) {
                    QueryParserConstants.PLUS -> {
                        jj_consume_token(QueryParserConstants.PLUS)
                        ret = MOD_REQ
                    }

                    QueryParserConstants.MINUS -> {
                        jj_consume_token(QueryParserConstants.MINUS)
                        ret = MOD_NOT
                    }

                    QueryParserConstants.NOT -> {
                        jj_consume_token(QueryParserConstants.NOT)
                        ret = MOD_NOT
                    }

                    else -> {
                        jj_la1[2] = jj_gen
                        jj_consume_token(-1)
                        throw ParseException()
                    }
                }
            }

            else -> {
                jj_la1[3] = jj_gen
            }
        }
        run { if ("" != null) return ret }
        throw Error("Missing return statement in function")
    }

    // This makes sure that there is no garbage after the query string
    @Throws(ParseException::class)
    override fun TopLevelQuery(field: String): Query {
        val q: Query
        q = Query(field)
        jj_consume_token(0)
        run { if ("" != null) return q }
        throw Error("Missing return statement in function")
    }

    @Throws(ParseException::class)
    fun Query(field: String): Query {
        val clauses: MutableList<BooleanClause> = mutableListOf()
        var q: Query
        var firstQuery: Query? = null
        var conj: Int
        var mods: Int
        if (jj_2_1(2)) {
            firstQuery = MultiTerm(field, clauses)
        } else {
            when (if (jj_ntk == -1) jj_ntk_f() else jj_ntk) {
                QueryParserConstants.NOT, QueryParserConstants.PLUS, QueryParserConstants.MINUS, QueryParserConstants.BAREOPER, QueryParserConstants.LPAREN, QueryParserConstants.STAR, QueryParserConstants.QUOTED, QueryParserConstants.TERM, QueryParserConstants.PREFIXTERM, QueryParserConstants.WILDTERM, QueryParserConstants.REGEXPTERM, QueryParserConstants.RANGEIN_START, QueryParserConstants.RANGEEX_START, QueryParserConstants.NUMBER -> {
                    mods = Modifiers()
                    q = Clause(field)
                    addClause(clauses, CONJ_NONE, mods, q)
                    if (mods == MOD_NONE) {
                        firstQuery = q
                    }
                }

                else -> {
                    jj_la1[4] = jj_gen
                    jj_consume_token(-1)
                    throw ParseException()
                }
            }
        }
        label_1@ while (true) {
            when (if (jj_ntk == -1) jj_ntk_f() else jj_ntk) {
                QueryParserConstants.AND, QueryParserConstants.OR, QueryParserConstants.NOT, QueryParserConstants.PLUS, QueryParserConstants.MINUS, QueryParserConstants.BAREOPER, QueryParserConstants.LPAREN, QueryParserConstants.STAR, QueryParserConstants.QUOTED, QueryParserConstants.TERM, QueryParserConstants.PREFIXTERM, QueryParserConstants.WILDTERM, QueryParserConstants.REGEXPTERM, QueryParserConstants.RANGEIN_START, QueryParserConstants.RANGEEX_START, QueryParserConstants.NUMBER -> {
                }

                else -> {
                    jj_la1[5] = jj_gen
                    break@label_1
                }
            }
            if (jj_2_2(2)) {
                MultiTerm(field, clauses)
            } else {
                when (if (jj_ntk == -1) jj_ntk_f() else jj_ntk) {
                    QueryParserConstants.AND, QueryParserConstants.OR, QueryParserConstants.NOT, QueryParserConstants.PLUS, QueryParserConstants.MINUS, QueryParserConstants.BAREOPER, QueryParserConstants.LPAREN, QueryParserConstants.STAR, QueryParserConstants.QUOTED, QueryParserConstants.TERM, QueryParserConstants.PREFIXTERM, QueryParserConstants.WILDTERM, QueryParserConstants.REGEXPTERM, QueryParserConstants.RANGEIN_START, QueryParserConstants.RANGEEX_START, QueryParserConstants.NUMBER -> {
                        conj = Conjunction()
                        mods = Modifiers()
                        q = Clause(field)
                        addClause(clauses, conj, mods, q)
                    }

                    else -> {
                        jj_la1[6] = jj_gen
                        jj_consume_token(-1)
                        throw ParseException()
                    }
                }
            }
        }
        if (clauses.size == 1 && firstQuery != null) {
            run { if ("" != null) return firstQuery }
        } else {
            run { if ("" != null) return getBooleanQuery(clauses)!! }
        }
        throw Error("Missing return statement in function")
    }

    @Throws(ParseException::class)
    fun Clause(field: String): Query {
        var field = field
        val q: Query
        var fieldToken: Token? = null
        var boost: Token? = null
        if (jj_2_3(2)) {
            when (if (jj_ntk == -1) jj_ntk_f() else jj_ntk) {
                QueryParserConstants.TERM -> {
                    fieldToken = jj_consume_token(QueryParserConstants.TERM)
                    jj_consume_token(QueryParserConstants.COLON)
                    field = discardEscapeChar(fieldToken.image!!)
                }

                QueryParserConstants.STAR -> {
                    jj_consume_token(QueryParserConstants.STAR)
                    jj_consume_token(QueryParserConstants.COLON)
                    field = "*"
                }

                else -> {
                    jj_la1[7] = jj_gen
                    jj_consume_token(-1)
                    throw ParseException()
                }
            }
        } else {
        }
        when (if (jj_ntk == -1) jj_ntk_f() else jj_ntk) {
            QueryParserConstants.BAREOPER, QueryParserConstants.STAR, QueryParserConstants.QUOTED, QueryParserConstants.TERM, QueryParserConstants.PREFIXTERM, QueryParserConstants.WILDTERM, QueryParserConstants.REGEXPTERM, QueryParserConstants.RANGEIN_START, QueryParserConstants.RANGEEX_START, QueryParserConstants.NUMBER -> {
                q = Term(field)
            }

            QueryParserConstants.LPAREN -> {
                jj_consume_token(QueryParserConstants.LPAREN)
                q = Query(field)
                jj_consume_token(QueryParserConstants.RPAREN)
                when (if (jj_ntk == -1) jj_ntk_f() else jj_ntk) {
                    QueryParserConstants.CARAT -> {
                        jj_consume_token(QueryParserConstants.CARAT)
                        boost = jj_consume_token(QueryParserConstants.NUMBER)
                    }

                    else -> {
                        jj_la1[8] = jj_gen
                    }
                }
            }

            else -> {
                jj_la1[9] = jj_gen
                jj_consume_token(-1)
                throw ParseException()
            }
        }
        run { if ("" != null) return handleBoost(q, boost) }
        throw Error("Missing return statement in function")
    }

    @Throws(ParseException::class)
    fun Term(field: String): Query {
        val term: Token
        var boost: Token? = null
        var fuzzySlop: Token? = null
        val goop1: Token
        val goop2: Token
        var prefix = false
        var wildcard = false
        var fuzzy = false
        var regexp = false
        var startInc = false
        var endInc = false
        val q: Query
        when (if (jj_ntk == -1) jj_ntk_f() else jj_ntk) {
            QueryParserConstants.BAREOPER, QueryParserConstants.STAR, QueryParserConstants.TERM, QueryParserConstants.PREFIXTERM, QueryParserConstants.WILDTERM, QueryParserConstants.REGEXPTERM, QueryParserConstants.NUMBER -> {
                when (if (jj_ntk == -1) jj_ntk_f() else jj_ntk) {
                    QueryParserConstants.TERM -> {
                        term = jj_consume_token(QueryParserConstants.TERM)
                    }

                    QueryParserConstants.STAR -> {
                        term = jj_consume_token(QueryParserConstants.STAR)
                        wildcard = true
                    }

                    QueryParserConstants.PREFIXTERM -> {
                        term = jj_consume_token(QueryParserConstants.PREFIXTERM)
                        prefix = true
                    }

                    QueryParserConstants.WILDTERM -> {
                        term = jj_consume_token(QueryParserConstants.WILDTERM)
                        wildcard = true
                    }

                    QueryParserConstants.REGEXPTERM -> {
                        term = jj_consume_token(QueryParserConstants.REGEXPTERM)
                        regexp = true
                    }

                    QueryParserConstants.NUMBER -> {
                        term = jj_consume_token(QueryParserConstants.NUMBER)
                    }

                    QueryParserConstants.BAREOPER -> {
                        term = jj_consume_token(QueryParserConstants.BAREOPER)
                        term.image = term.image!!.substring(0, 1)
                    }

                    else -> {
                        jj_la1[10] = jj_gen
                        jj_consume_token(-1)
                        throw ParseException()
                    }
                }
                when (if (jj_ntk == -1) jj_ntk_f() else jj_ntk) {
                    QueryParserConstants.CARAT, QueryParserConstants.FUZZY_SLOP -> {
                        when (if (jj_ntk == -1) jj_ntk_f() else jj_ntk) {
                            QueryParserConstants.CARAT -> {
                                jj_consume_token(QueryParserConstants.CARAT)
                                boost =
                                    jj_consume_token(QueryParserConstants.NUMBER)
                                when (if (jj_ntk == -1) jj_ntk_f() else jj_ntk) {
                                    QueryParserConstants.FUZZY_SLOP -> {
                                        fuzzySlop =
                                            jj_consume_token(QueryParserConstants.FUZZY_SLOP)
                                        fuzzy = true
                                    }

                                    else -> {
                                        jj_la1[11] = jj_gen
                                    }
                                }
                            }

                            QueryParserConstants.FUZZY_SLOP -> {
                                fuzzySlop =
                                    jj_consume_token(QueryParserConstants.FUZZY_SLOP)
                                fuzzy = true
                                when (if (jj_ntk == -1) jj_ntk_f() else jj_ntk) {
                                    QueryParserConstants.CARAT -> {
                                        jj_consume_token(QueryParserConstants.CARAT)
                                        boost =
                                            jj_consume_token(QueryParserConstants.NUMBER)
                                    }

                                    else -> {
                                        jj_la1[12] = jj_gen
                                    }
                                }
                            }

                            else -> {
                                jj_la1[13] = jj_gen
                                jj_consume_token(-1)
                                throw ParseException()
                            }
                        }
                    }

                    else -> {
                        jj_la1[14] = jj_gen
                    }
                }
                q = handleBareTokenQuery(field, term, fuzzySlop!!, prefix, wildcard, fuzzy, regexp)
            }

            QueryParserConstants.RANGEIN_START, QueryParserConstants.RANGEEX_START -> {
                when (if (jj_ntk == -1) jj_ntk_f() else jj_ntk) {
                    QueryParserConstants.RANGEIN_START -> {
                        jj_consume_token(QueryParserConstants.RANGEIN_START)
                        startInc = true
                    }

                    QueryParserConstants.RANGEEX_START -> {
                        jj_consume_token(QueryParserConstants.RANGEEX_START)
                    }

                    else -> {
                        jj_la1[15] = jj_gen
                        jj_consume_token(-1)
                        throw ParseException()
                    }
                }
                when (if (jj_ntk == -1) jj_ntk_f() else jj_ntk) {
                    QueryParserConstants.RANGE_GOOP -> {
                        goop1 = jj_consume_token(QueryParserConstants.RANGE_GOOP)
                    }

                    QueryParserConstants.RANGE_QUOTED -> {
                        goop1 =
                            jj_consume_token(QueryParserConstants.RANGE_QUOTED)
                    }

                    QueryParserConstants.RANGE_TO -> {
                        goop1 = jj_consume_token(QueryParserConstants.RANGE_TO)
                    }

                    else -> {
                        jj_la1[16] = jj_gen
                        jj_consume_token(-1)
                        throw ParseException()
                    }
                }
                jj_consume_token(QueryParserConstants.RANGE_TO)
                when (if (jj_ntk == -1) jj_ntk_f() else jj_ntk) {
                    QueryParserConstants.RANGE_GOOP -> {
                        goop2 = jj_consume_token(QueryParserConstants.RANGE_GOOP)
                    }

                    QueryParserConstants.RANGE_QUOTED -> {
                        goop2 =
                            jj_consume_token(QueryParserConstants.RANGE_QUOTED)
                    }

                    QueryParserConstants.RANGE_TO -> {
                        goop2 = jj_consume_token(QueryParserConstants.RANGE_TO)
                    }

                    else -> {
                        jj_la1[17] = jj_gen
                        jj_consume_token(-1)
                        throw ParseException()
                    }
                }
                when (if (jj_ntk == -1) jj_ntk_f() else jj_ntk) {
                    QueryParserConstants.RANGEIN_END -> {
                        jj_consume_token(QueryParserConstants.RANGEIN_END)
                        endInc = true
                    }

                    QueryParserConstants.RANGEEX_END -> {
                        jj_consume_token(QueryParserConstants.RANGEEX_END)
                    }

                    else -> {
                        jj_la1[18] = jj_gen
                        jj_consume_token(-1)
                        throw ParseException()
                    }
                }
                when (if (jj_ntk == -1) jj_ntk_f() else jj_ntk) {
                    QueryParserConstants.CARAT -> {
                        jj_consume_token(QueryParserConstants.CARAT)
                        boost = jj_consume_token(QueryParserConstants.NUMBER)
                    }

                    else -> {
                        jj_la1[19] = jj_gen
                    }
                }
                var startOpen = false
                var endOpen = false
                if (goop1.kind == QueryParserConstants.RANGE_QUOTED) {
                    goop1.image = goop1.image!!.substring(1, goop1.image!!.length - 1)
                } else if ("*" == goop1.image) {
                    startOpen = true
                }
                if (goop2.kind == QueryParserConstants.RANGE_QUOTED) {
                    goop2.image = goop2.image!!.substring(1, goop2.image!!.length - 1)
                } else if ("*" == goop2.image) {
                    endOpen = true
                }
                q = getRangeQuery(
                    field,
                    if (startOpen) null else discardEscapeChar(goop1.image!!),
                    if (endOpen) null else discardEscapeChar(goop2.image!!),
                    startInc,
                    endInc
                )
            }

            QueryParserConstants.QUOTED -> {
                term = jj_consume_token(QueryParserConstants.QUOTED)
                when (if (jj_ntk == -1) jj_ntk_f() else jj_ntk) {
                    QueryParserConstants.CARAT, QueryParserConstants.FUZZY_SLOP -> {
                        when (if (jj_ntk == -1) jj_ntk_f() else jj_ntk) {
                            QueryParserConstants.CARAT -> {
                                jj_consume_token(QueryParserConstants.CARAT)
                                boost =
                                    jj_consume_token(QueryParserConstants.NUMBER)
                                when (if (jj_ntk == -1) jj_ntk_f() else jj_ntk) {
                                    QueryParserConstants.FUZZY_SLOP -> {
                                        fuzzySlop =
                                            jj_consume_token(QueryParserConstants.FUZZY_SLOP)
                                        fuzzy = true
                                    }

                                    else -> {
                                        jj_la1[20] = jj_gen
                                    }
                                }
                            }

                            QueryParserConstants.FUZZY_SLOP -> {
                                fuzzySlop =
                                    jj_consume_token(QueryParserConstants.FUZZY_SLOP)
                                fuzzy = true
                                when (if (jj_ntk == -1) jj_ntk_f() else jj_ntk) {
                                    QueryParserConstants.CARAT -> {
                                        jj_consume_token(QueryParserConstants.CARAT)
                                        boost =
                                            jj_consume_token(QueryParserConstants.NUMBER)
                                    }

                                    else -> {
                                        jj_la1[21] = jj_gen
                                    }
                                }
                            }

                            else -> {
                                jj_la1[22] = jj_gen
                                jj_consume_token(-1)
                                throw ParseException()
                            }
                        }
                    }

                    else -> {
                        jj_la1[23] = jj_gen
                    }
                }
                q = handleQuotedTerm(field, term, fuzzySlop)
            }

            else -> {
                jj_la1[24] = jj_gen
                jj_consume_token(-1)
                throw ParseException()
            }
        }
        run { if ("" != null) return handleBoost(q, boost) }
        throw Error("Missing return statement in function")
    }

    /** Returns the first query if splitOnWhitespace=true or otherwise the entire produced query  */
    @Throws(ParseException::class)
    fun MultiTerm(
        field: String,
        clauses: MutableList<BooleanClause>
    ): Query {
        var whitespace: Token
        var followingText: Token
        var firstQuery: Query? = null
        val text: Token = jj_consume_token(QueryParserConstants.TERM)
        if (splitOnWhitespace) {
            firstQuery = getFieldQuery(field, discardEscapeChar(text.image!!), false)
            addClause(
                clauses,
                CONJ_NONE,
                MOD_NONE,
                firstQuery
            )
        }
        if (getToken(1).kind == QueryParserConstants.TERM && allowedPostMultiTerm(
                getToken(2).kind
            )
        ) {
        } else {
            jj_consume_token(-1)
            throw ParseException()
        }
        label_2@ while (true) {
            followingText = jj_consume_token(QueryParserConstants.TERM)
            if (splitOnWhitespace) {
                val q: Query =
                    getFieldQuery(field, discardEscapeChar(followingText.image!!), false)
                addClause(
                    clauses,
                    CONJ_NONE,
                    MOD_NONE,
                    q
                )
            } else { // build up the text to send to analysis
                text.image += " " + followingText.image
            }
            if (getToken(1).kind == QueryParserConstants.TERM && allowedPostMultiTerm(
                    getToken(2).kind
                )
            ) {
            } else {
                break@label_2
            }
        }
        if (!splitOnWhitespace) {
            firstQuery = getFieldQuery(field, discardEscapeChar(text.image!!), false)
            addMultiTermClauses(clauses, firstQuery)
        }
        run { if ("" != null) return firstQuery!! }
        throw Error("Missing return statement in function")
    }

    private fun jj_2_1(xla: Int): Boolean {
        jj_la = xla
        jj_scanpos = token
        jj_lastpos = jj_scanpos
        return try {
            (!jj_3_1())
        } catch (ls: LookaheadSuccess) {
            true
        } finally {
            jj_save(0, xla)
        }
    }

    private fun jj_2_2(xla: Int): Boolean {
        jj_la = xla
        jj_scanpos = token
        jj_lastpos = jj_scanpos
        return try {
            (!jj_3_2())
        } catch (ls: LookaheadSuccess) {
            true
        } finally {
            jj_save(1, xla)
        }
    }

    private fun jj_2_3(xla: Int): Boolean {
        jj_la = xla
        jj_scanpos = token
        jj_lastpos = jj_scanpos
        return try {
            (!jj_3_3())
        } catch (ls: LookaheadSuccess) {
            true
        } finally {
            jj_save(2, xla)
        }
    }

    private fun jj_3R_MultiTerm_381_3_3(): Boolean {
        if (jj_scan_token(QueryParserConstants.TERM)) return true
        jj_lookingAhead = true
        jj_semLA =
            getToken(1).kind == QueryParserConstants.TERM && allowedPostMultiTerm(
                getToken(2).kind
            )
        jj_lookingAhead = false
        if (!jj_semLA || jj_3R_MultiTerm_389_3_6()) return true
        var xsp: Token?
        if (jj_3R_MultiTerm_391_5_7()) return true
        while (true) {
            xsp = jj_scanpos
            if (jj_3R_MultiTerm_391_5_7()) {
                jj_scanpos = xsp
                break
            }
        }
        return false
    }

    private fun jj_3R_MultiTerm_389_3_6(): Boolean {
        return false
    }

    private fun jj_3R_Clause_306_9_5(): Boolean {
        if (jj_scan_token(QueryParserConstants.STAR)) return true
        if (jj_scan_token(QueryParserConstants.COLON)) return true
        return false
    }

    private fun jj_3R_Clause_305_7_4(): Boolean {
        if (jj_scan_token(QueryParserConstants.TERM)) return true
        if (jj_scan_token(QueryParserConstants.COLON)) return true
        return false
    }

    private fun jj_3_2(): Boolean {
        if (jj_3R_MultiTerm_381_3_3()) return true
        return false
    }

    private fun jj_3_1(): Boolean {
        if (jj_3R_MultiTerm_381_3_3()) return true
        return false
    }

    private fun jj_3R_MultiTerm_391_5_7(): Boolean {
        if (jj_scan_token(QueryParserConstants.TERM)) return true
        return false
    }

    private fun jj_3_3(): Boolean {
        val xsp: Token? = jj_scanpos
        if (jj_3R_Clause_305_7_4()) {
            jj_scanpos = xsp
            if (jj_3R_Clause_306_9_5()) return true
        }
        return false
    }

    /** Generated Token Manager.  */
    var token_source: QueryParserTokenManager

    /** Current token.  */
    var token: Token?

    /** Next token.  */
    var jj_nt: Token? = null
    private var jj_ntk: Int
    private var jj_scanpos: Token? = null
    private var jj_lastpos: Token? = null
    private var jj_la = 0

    /** Whether we are looking ahead.  */
    private var jj_lookingAhead = false
    private var jj_semLA = false
    private var jj_gen: Int
    private val jj_la1 = IntArray(25)
    private val jj_2_rtns: Array<JJCalls> = kotlin.arrayOfNulls<JJCalls>(3) as Array<JJCalls>
    private var jj_rescan = false
    private var jj_gc = 0

    /** Constructor with user supplied CharStream.  */
    protected constructor(stream: CharStream) {
        token_source = QueryParserTokenManager(stream)
        token = Token()
        jj_ntk = -1
        jj_gen = 0
        for (i in 0..24) jj_la1[i] = -1
        for (i in jj_2_rtns.indices) jj_2_rtns[i] = JJCalls()
    }

    /** Reinitialise.  */
    override fun ReInit(stream: CharStream) {
        token_source.ReInit(stream)
        token = Token()
        jj_ntk = -1
        jj_lookingAhead = false
        jj_gen = 0
        for (i in 0..24) jj_la1[i] = -1
        for (i in jj_2_rtns.indices) jj_2_rtns[i] = JJCalls()
    }

    /** Constructor with generated Token Manager.  */
    protected constructor(tm: QueryParserTokenManager) {
        token_source = tm
        token = Token()
        jj_ntk = -1
        jj_gen = 0
        for (i in 0..24) jj_la1[i] = -1
        for (i in jj_2_rtns.indices) jj_2_rtns[i] = JJCalls()
    }

    /** Reinitialise.  */
    fun ReInit(tm: QueryParserTokenManager) {
        token_source = tm
        token = Token()
        jj_ntk = -1
        jj_gen = 0
        for (i in 0..24) jj_la1[i] = -1
        for (i in jj_2_rtns.indices) jj_2_rtns[i] = JJCalls()
    }

    @Throws(ParseException::class)
    private fun jj_consume_token(kind: Int): Token {
        val oldToken: Token?
        if ((token.also { oldToken = it })!!.next != null) token = token!!.next
        else {
            token!!.next = token_source.nextToken
            token = token!!.next
        }
        jj_ntk = -1
        if (token!!.kind == kind) {
            jj_gen++
            if (++jj_gc > 100) {
                jj_gc = 0
                for (i in jj_2_rtns.indices) {
                    var c: JJCalls = jj_2_rtns[i]
                    while (c != null) {
                        if (c.gen < jj_gen) c.first = null
                        c = c.next!!
                    }
                }
            }
            return token!!
        }
        token = oldToken
        jj_kind = kind
        throw generateParseException()
    }

    private class LookaheadSuccess : Error() {
        fun fillInStackTrace(): Throwable {
            return this
        }
    }

    private fun jj_scan_token(kind: Int): Boolean {
        if (jj_scanpos === jj_lastpos) {
            jj_la--
            if (jj_scanpos!!.next == null) {
                jj_scanpos!!.next = token_source.nextToken
                jj_scanpos = jj_scanpos!!.next
                jj_lastpos = jj_scanpos
            } else {
                jj_scanpos = jj_scanpos!!.next
                jj_lastpos = jj_scanpos
            }
        } else {
            jj_scanpos = jj_scanpos!!.next
        }
        if (jj_rescan) {
            var i = 0
            var tok: Token? = token
            while (tok != null && tok !== jj_scanpos) {
                i++
                tok = tok.next
            }
            if (tok != null) jj_add_error_token(kind, i)
        }
        if (jj_scanpos!!.kind != kind) return true
        if (jj_la == 0 && jj_scanpos === jj_lastpos) throw jj_ls
        return false
    }


    val nextToken: Token?
        /** Get the next Token.  */
        get() {
            if (token!!.next != null) token = token!!.next
            else {
                token!!.next = token_source.nextToken
                token = token!!.next
            }
            jj_ntk = -1
            jj_gen++
            return token
        }

    /** Get the specific Token.  */
    fun getToken(index: Int): Token {
        var t: Token? = if (jj_lookingAhead) jj_scanpos else token
        for (i in 0..<index) {
            if (t!!.next != null) t = t.next
            else {
                t.next = token_source.nextToken
                t = t.next
            }
        }
        return t!!
    }

    private fun jj_ntk_f(): Int {
        if ((token!!.next.also { jj_nt = it }) == null) return ((token_source.nextToken
            .also { token!!.next = it }).kind.also { jj_ntk = it })
        else return (jj_nt!!.kind.also { jj_ntk = it })
    }

    private val jj_expentries: MutableList<IntArray> = mutableListOf()
    private lateinit var jj_expentry: IntArray
    private var jj_kind = -1
    private val jj_lasttokens = IntArray(100)
    private var jj_endpos = 0

    private fun jj_add_error_token(kind: Int, pos: Int) {
        if (pos >= 100) {
            return
        }

        if (pos == jj_endpos + 1) {
            jj_lasttokens[jj_endpos++] = kind
        } else if (jj_endpos != 0) {
            jj_expentry = IntArray(jj_endpos)

            for (i in 0..<jj_endpos) {
                jj_expentry[i] = jj_lasttokens[i]
            }

            for (oldentry in jj_expentries) {
                if (oldentry.size == jj_expentry.size) {
                    var isMatched = true

                    for (i in jj_expentry.indices) {
                        if (oldentry[i] != jj_expentry[i]) {
                            isMatched = false
                            break
                        }
                    }
                    if (isMatched) {
                        jj_expentries.add(jj_expentry)
                        break
                    }
                }
            }

            if (pos != 0) {
                jj_lasttokens[(pos.also { jj_endpos = it }) - 1] = kind
            }
        }
    }

    /** Generate ParseException.  */
    fun generateParseException(): ParseException {
        jj_expentries.clear()
        val la1tokens = BooleanArray(33)
        if (jj_kind >= 0) {
            la1tokens[jj_kind] = true
            jj_kind = -1
        }
        for (i in 0..24) {
            if (jj_la1[i] == jj_gen) {
                for (j in 0..31) {
                    if ((jj_la1_0[i] and (1 shl j)) != 0) {
                        la1tokens[j] = true
                    }
                    if ((jj_la1_1[i] and (1 shl j)) != 0) {
                        la1tokens[32 + j] = true
                    }
                }
            }
        }
        for (i in 0..32) {
            if (la1tokens[i]) {
                jj_expentry = IntArray(1)
                jj_expentry[0] = i
                jj_expentries.add(jj_expentry)
            }
        }
        jj_endpos = 0
        jj_rescan_token()
        jj_add_error_token(0, 0)
        val exptokseq = kotlin.arrayOfNulls<IntArray>(jj_expentries.size) as Array<IntArray>
        for (i in jj_expentries.indices) {
            exptokseq[i] = jj_expentries[i]
        }
        return ParseException(
            token!!,
            exptokseq,
            QueryParserConstants.tokenImage
        )
    }

    private var trace_enabled = false

    /** Trace enabled.  */
    fun trace_enabled(): Boolean {
        return trace_enabled
    }

    /** Enable tracing.  */
    fun enable_tracing() {
    }

    /** Disable tracing.  */
    fun disable_tracing() {
    }

    private fun jj_rescan_token() {
        jj_rescan = true
        for (i in 0..2) {
            try {
                var p: JJCalls? = jj_2_rtns[i]

                do {
                    if (p!!.gen > jj_gen) {
                        jj_la = p.arg
                        jj_scanpos = p.first
                        jj_lastpos = jj_scanpos
                        when (i) {
                            0 -> jj_3_1()
                            1 -> jj_3_2()
                            2 -> jj_3_3()
                        }
                    }
                    p = p.next
                } while (p != null)
            } catch (ls: LookaheadSuccess) {
            }
        }
        jj_rescan = false
    }

    private fun jj_save(index: Int, xla: Int) {
        var p: JJCalls? = jj_2_rtns[index]
        while (p!!.gen > jj_gen) {
            if (p.next == null) {
                p.next = JJCalls()
                p = p.next
                break
            }
            p = p.next
        }

        p!!.gen = jj_gen + xla - jj_la
        p.first = token
        p.arg = xla
    }

    internal class JJCalls {
        var gen: Int = 0
        var first: Token? = null
        var arg: Int = 0
        var next: JJCalls? = null
    }

    companion object {
        /** default split on whitespace behavior  */
        const val DEFAULT_SPLIT_ON_WHITESPACE: Boolean = false

        private val disallowedPostMultiTerm
                : IntHashSet = IntHashSet.from(
            QueryParserConstants.COLON,
            QueryParserConstants.STAR,
            QueryParserConstants.FUZZY_SLOP,
            QueryParserConstants.CARAT,
            QueryParserConstants.AND,
            QueryParserConstants.OR
        )

        private fun allowedPostMultiTerm(tokenKind: Int): Boolean {
            return !disallowedPostMultiTerm.contains(tokenKind)
        }

        private lateinit var jj_la1_0: IntArray
        private lateinit var jj_la1_1: IntArray

        init {
            jj_la1_init_0()
            jj_la1_init_1()
        }

        private fun jj_la1_init_0() {
            jj_la1_0 = intArrayOf(
                0x300,
                0x300,
                0x1c00,
                0x1c00,
                0xfda7c00,
                0xfda7f00,
                0xfda7f00,
                0x120000,
                0x40000,
                0xfda6000,
                0x9d22000,
                0x200000,
                0x40000,
                0x240000,
                0x240000,
                0x6000000,
                -0x70000000,
                -0x70000000,
                0x60000000,
                0x40000,
                0x200000,
                0x40000,
                0x240000,
                0x240000,
                0xfda2000,
            )
        }

        private fun jj_la1_init_1() {
            jj_la1_1 = intArrayOf(
                0x0,
                0x0,
                0x0,
                0x0,
                0x0,
                0x0,
                0x0,
                0x0,
                0x0,
                0x0,
                0x0,
                0x0,
                0x0,
                0x0,
                0x0,
                0x0,
                0x1,
                0x1,
                0x0,
                0x0,
                0x0,
                0x0,
                0x0,
                0x0,
                0x0,
            )
        }

        private val jj_ls = LookaheadSuccess()
    }
}
